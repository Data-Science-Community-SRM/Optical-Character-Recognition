# -*- coding: utf-8 -*-
"""Structured_Images_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bc1bYBxAPGwsIONAjZDC2eRY4Bpm1W7v
"""

#!sudo apt install tesseract-ocr
#!pip install pytesseract

import numpy as np
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import argparse
import time
import sys
from PIL import Image
from scipy.ndimage import interpolation as inter
from matplotlib import pyplot as plt
import tempfile

#from google.colab import files
#uploaded = files.upload()
def structured(img):
    #image_path = "/content/8.png"
    image_path = img

    IMAGE_SIZE = 1800


    def set_image_dpi(file_path):

        im = Image.open(file_path)
        length_x, width_y = im.size
        factor = max(1, int(IMAGE_SIZE / length_x))
        size = factor * length_x, factor * width_y
        # size = (1800, 1800)
        im_resized = im.resize(size, Image.ANTIALIAS)
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        temp_filename = temp_file.name
        im_resized.save(temp_filename, dpi=(300, 300))
        return temp_filename
    

    #img= cv2.imread(img)
    #im = Image.open(img)

    #show image
    #im.show()

    #noise removal and smoothening
    BINARY_THREHOLD = 180

    def image_smoothening(img):
        ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)
        ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        blur = cv2.GaussianBlur(th2, (1, 1), 0)
        ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        return th3

    def remove_noise_and_smooth(file_name):
        img = cv2.imread(file_name, 0)
        filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 41)
        kernel = np.ones((1, 1), np.uint8)
        opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)
        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)
        img = image_smoothening(img)
        or_image = cv2.bitwise_or(img, closing)
        return or_image

    img_dpi = set_image_dpi(image_path)

    import cv2
    import numpy as np

    # read the image
    img = cv2.imread(img_dpi)

    # convert to gray
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    # apply morphology
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT , (3,3))
    smooth = cv2.morphologyEx(gray, cv2.MORPH_DILATE, kernel)

    # alternate blur in place of morphology
    #smooth = cv2.GaussianBlur(gray, (15,15), 0)

    # divide gray by morphology image
    division = cv2.divide(gray, smooth, scale=255)

    # threshold
    result = cv2.threshold(division, 0, 255, cv2.THRESH_OTSU )[1] 

    # save results
    cv2.imwrite('img_thresh.png',result)

    import cv2
    import numpy as np
    from scipy.ndimage import interpolation as inter

    def correct_skew(image, delta=1, limit=5):
        def determine_score(arr, angle):
            data = inter.rotate(arr, angle, reshape=False, order=0)
            histogram = np.sum(data, axis=1)
            score = np.sum((histogram[1:] - histogram[:-1]) ** 2)
            return histogram, score

        #img = cv2.imread(image, cv2.IMREAD_COLOR)


        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1] 

        scores = []
        angles = np.arange(-limit, limit + delta, delta)
        for angle in angles:
            histogram, score = determine_score(thresh, angle)
            scores.append(score)

        best_angle = angles[scores.index(max(scores))]

        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, best_angle, 1.0)
        rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, \
                borderMode=cv2.BORDER_REPLICATE)

        return best_angle, rotated

    img3 = cv2.imread(img_dpi)
    angle, rotated = correct_skew(img3)

    extractedInformation = pytesseract.image_to_string(rotated)
    #print(extractedInformation)

    #print(pytesseract.image_to_boxes(rotated))
    return extractedInformation